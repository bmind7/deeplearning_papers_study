{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST('./datasets/', download=True, train=True, transform=transform)\n",
    "valset = datasets.MNIST('./datasets', download=True, train=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move everything to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1750cef4e50>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=16, bias=True)\n",
      "  (1): Sigmoid()\n",
      "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (3): Sigmoid()\n",
      "  (4): Linear(in_features=16, out_features=10, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_sizes = [16, 16]\n",
    "output_size = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.Sigmoid(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.Sigmoid(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Sigmoid())\n",
    "\n",
    "model.cuda()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc():\n",
    "    correct_count, all_count = 0, 0\n",
    "    for images, labels in valloader:\n",
    "        for i in range(len(labels)):\n",
    "            img = images[i].view(1, 784).cuda()\n",
    "            with torch.no_grad():\n",
    "                logps = model(img)\n",
    "\n",
    "            output_labels = logps.flatten().tolist()\n",
    "            pred_label = output_labels.index(max(output_labels))\n",
    "            true_label = labels.numpy()[i]\n",
    "            if(true_label == pred_label):\n",
    "                correct_count += 1\n",
    "            all_count += 1\n",
    "\n",
    "    print(\"Number Of Images Tested =\", all_count)\n",
    "    print(\"\\nModel Accuracy =\", (correct_count/all_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 0.012088260649622026\n",
      "Number Of Images Tested = 10000\n",
      "\n",
      "Model Accuracy = 0.9249\n",
      "Epoch 1 - Training loss: 0.012035591099763722\n",
      "Number Of Images Tested = 10000\n",
      "\n",
      "Model Accuracy = 0.9248\n",
      "\n",
      "Training Time (in minutes) = 0.6479721347490947\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.0)\n",
    "time0 = time()\n",
    "epochs = 2\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1).cuda()\n",
    "\n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(images)\n",
    "        labels = nn.functional.one_hot(labels, num_classes=10).float().cuda()\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        #This is where the model learns by backpropagating\n",
    "        loss.backward()\n",
    "\n",
    "        #And optimizes its weights here\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e,\n",
    "              running_loss/len(trainloader)))\n",
    "        calc_acc()\n",
    "\n",
    "print(\"\\nTraining Time (in minutes) =\", (time()-time0)/60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/000b.pt')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7cb0abe6a156ed333ad4fd07d9af989e8f53906384bd66e80c5bbb553a4eaba7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
